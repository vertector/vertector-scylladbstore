{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search with ScyllaDB and Google Gemini\n",
    "\n",
    "This notebook demonstrates semantic search capabilities using:\n",
    "- **AsyncScyllaDBStore** - Vector-enabled key-value store\n",
    "- **Google Gemini Embeddings** - 3072-dimensional embeddings\n",
    "- **sklearn cosine_similarity** - Efficient similarity computation\n",
    "\n",
    "## Prerequisites\n",
    "- ScyllaDB running on localhost:9042\n",
    "- GOOGLE_API_KEY in .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from vertector_scylladbstore import AsyncScyllaDBStore\n",
    "\n",
    "# Load environment variables\n",
    "def load_env():\n",
    "    env_path = Path(\".\") / \".env\"\n",
    "    if env_path.exists():\n",
    "        with open(env_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#') and '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    value = value.strip().strip('\"').strip(\"'\")\n",
    "                    os.environ[key.strip()] = value\n",
    "\n",
    "load_env()\n",
    "\n",
    "# Verify API key\n",
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"⚠️  GOOGLE_API_KEY not found in .env file\")\n",
    "else:\n",
    "    print(\"✓ GOOGLE_API_KEY loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Gemini Embeddings\n",
    "\n",
    "Google Gemini supports different task types:\n",
    "- `RETRIEVAL_DOCUMENT` - For embedding documents to store\n",
    "- `RETRIEVAL_QUERY` - For embedding search queries\n",
    "- `SEMANTIC_SIMILARITY` - General similarity tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings with RETRIEVAL_DOCUMENT task type\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\",\n",
    "    task_type=\"RETRIEVAL_DOCUMENT\"\n",
    ")\n",
    "\n",
    "# Test embedding generation\n",
    "test_text = \"Hello, world!\"\n",
    "test_embedding = embeddings.embed_query(test_text)\n",
    "\n",
    "print(f\"✓ Embeddings initialized\")\n",
    "print(f\"  Model: gemini-embedding-001\")\n",
    "print(f\"  Dimensions: {len(test_embedding)}\")\n",
    "print(f\"  Sample (first 5): {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create ScyllaDB Store with Semantic Search\n",
    "\n",
    "Configure the store with `IndexConfig` to enable semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IndexConfig for semantic search\n",
    "index_config = {\n",
    "    \"dims\": 3072,  # Gemini embedding-001 dimensions\n",
    "    \"embed\": embeddings,  # Pass embeddings instance\n",
    "    \"fields\": [\"$\"]  # Embed entire value dict\n",
    "}\n",
    "\n",
    "# Create store (we'll use it in async context)\n",
    "print(\"✓ IndexConfig created\")\n",
    "print(f\"  Dimensions: {index_config['dims']}\")\n",
    "print(f\"  Fields to embed: {index_config['fields']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insert Documents with Auto-Embedding\n",
    "\n",
    "When you call `aput()`, embeddings are generated automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def insert_documents():\n",
    "    \"\"\"Insert sample documents with automatic embedding.\"\"\"\n",
    "    \n",
    "    async with AsyncScyllaDBStore.from_contact_points(\n",
    "        contact_points=[\"127.0.0.1\"],\n",
    "        keyspace=\"notebook_demo\",\n",
    "        index=index_config,\n",
    "        enable_circuit_breaker=False\n",
    "    ) as store:\n",
    "        \n",
    "        # Setup schema\n",
    "        await store.setup()\n",
    "        print(\"✓ Store created and schema initialized\\n\")\n",
    "        \n",
    "        # Sample documents about different topics\n",
    "        documents = [\n",
    "            {\n",
    "                \"id\": \"ai1\",\n",
    "                \"title\": \"Machine Learning Basics\",\n",
    "                \"content\": \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without explicit programming.\",\n",
    "                \"category\": \"AI\",\n",
    "                \"tags\": [\"ml\", \"ai\", \"data-science\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"ai2\",\n",
    "                \"title\": \"Neural Networks\",\n",
    "                \"content\": \"Deep learning uses neural networks with multiple layers to process complex patterns in data, revolutionizing computer vision and natural language processing.\",\n",
    "                \"category\": \"AI\",\n",
    "                \"tags\": [\"deep-learning\", \"neural-nets\", \"ai\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"db1\",\n",
    "                \"title\": \"NoSQL Databases\",\n",
    "                \"content\": \"ScyllaDB is a high-performance NoSQL database that provides low-latency and high-throughput for modern applications, compatible with Apache Cassandra.\",\n",
    "                \"category\": \"Database\",\n",
    "                \"tags\": [\"nosql\", \"database\", \"scylladb\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"prog1\",\n",
    "                \"title\": \"Python Programming\",\n",
    "                \"content\": \"Python is a versatile programming language widely used for web development, data science, automation, and machine learning applications.\",\n",
    "                \"category\": \"Programming\",\n",
    "                \"tags\": [\"python\", \"coding\", \"development\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"ai3\",\n",
    "                \"title\": \"Vector Embeddings\",\n",
    "                \"content\": \"Vector embeddings represent text, images, or other data as numerical vectors in high-dimensional space, enabling semantic similarity searches.\",\n",
    "                \"category\": \"AI\",\n",
    "                \"tags\": [\"embeddings\", \"vectors\", \"semantic-search\"]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"cloud1\",\n",
    "                \"title\": \"Cloud Computing\",\n",
    "                \"content\": \"Cloud platforms provide scalable infrastructure for deploying applications, offering services like compute, storage, and managed databases.\",\n",
    "                \"category\": \"Cloud\",\n",
    "                \"tags\": [\"cloud\", \"aws\", \"infrastructure\"]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Insert documents\n",
    "        print(\"Inserting documents with auto-embedding...\\n\")\n",
    "        for doc in documents:\n",
    "            await store.aput(\n",
    "                namespace=(\"knowledge\", \"tech\"),\n",
    "                key=doc[\"id\"],\n",
    "                value=doc\n",
    "            )\n",
    "            print(f\"  ✓ {doc['id']:8} - {doc['title']}\")\n",
    "        \n",
    "        print(f\"\\n✓ Inserted {len(documents)} documents with embeddings\")\n",
    "        return len(documents)\n",
    "\n",
    "# Run insertion\n",
    "doc_count = await insert_documents()\n",
    "print(f\"\\nReady for semantic search with {doc_count} documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Semantic Search - Basic Queries\n",
    "\n",
    "Search using natural language queries. Results are ranked by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def semantic_search(query_text, limit=3):\n",
    "    \"\"\"Perform semantic search and display results.\"\"\"\n",
    "    \n",
    "    async with AsyncScyllaDBStore.from_contact_points(\n",
    "        contact_points=[\"127.0.0.1\"],\n",
    "        keyspace=\"notebook_demo\",\n",
    "        index=index_config,\n",
    "        enable_circuit_breaker=False\n",
    "    ) as store:\n",
    "        \n",
    "        await store.setup()  # Ensure prepared statements are ready\n",
    "        \n",
    "        # Perform semantic search\n",
    "        results = await store.asearch(\n",
    "            (\"knowledge\", \"tech\"),  # namespace_prefix (positional-only)\n",
    "            query=query_text,\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test query 1: AI-related\n",
    "print(\"Query: 'What is artificial intelligence and how does it work?'\\n\")\n",
    "results = await semantic_search(\"What is artificial intelligence and how does it work?\")\n",
    "\n",
    "for i, item in enumerate(results, 1):\n",
    "    print(f\"{i}. Score: {item.score:.4f}\")\n",
    "    print(f\"   Title: {item.value['title']}\")\n",
    "    print(f\"   Category: {item.value['category']}\")\n",
    "    print(f\"   Content: {item.value['content'][:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 2: Database-related\n",
    "print(\"Query: 'Tell me about high-performance databases'\\n\")\n",
    "results = await semantic_search(\"Tell me about high-performance databases\")\n",
    "\n",
    "for i, item in enumerate(results, 1):\n",
    "    print(f\"{i}. Score: {item.score:.4f}\")\n",
    "    print(f\"   Title: {item.value['title']}\")\n",
    "    print(f\"   Category: {item.value['category']}\")\n",
    "    print(f\"   Content: {item.value['content'][:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query 3: Vector/Embedding-related\n",
    "print(\"Query: 'How do vector representations work for similarity?'\\n\")\n",
    "results = await semantic_search(\"How do vector representations work for similarity?\")\n",
    "\n",
    "for i, item in enumerate(results, 1):\n",
    "    print(f\"{i}. Score: {item.score:.4f}\")\n",
    "    print(f\"   Title: {item.value['title']}\")\n",
    "    print(f\"   Category: {item.value['category']}\")\n",
    "    print(f\"   Content: {item.value['content'][:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combined Filter + Semantic Search\n",
    "\n",
    "Filter results by metadata, then rank by semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def filtered_semantic_search(query_text, filter_dict, limit=3):\n",
    "    \"\"\"Perform filtered semantic search.\"\"\"\n",
    "    \n",
    "    async with AsyncScyllaDBStore.from_contact_points(\n",
    "        contact_points=[\"127.0.0.1\"],\n",
    "        keyspace=\"notebook_demo\",\n",
    "        index=index_config,\n",
    "        enable_circuit_breaker=False\n",
    "    ) as store:\n",
    "        \n",
    "        await store.setup()  # Ensure prepared statements are ready\n",
    "        \n",
    "        results = await store.asearch(\n",
    "            (\"knowledge\", \"tech\"),\n",
    "            query=query_text,\n",
    "            filter=filter_dict,\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Search only AI category documents\n",
    "print(\"Query: 'learning and intelligence'\")\n",
    "print(\"Filter: category = 'AI'\\n\")\n",
    "\n",
    "results = await filtered_semantic_search(\n",
    "    \"learning and intelligence\",\n",
    "    {\"category\": \"AI\"}\n",
    ")\n",
    "\n",
    "for i, item in enumerate(results, 1):\n",
    "    print(f\"{i}. Score: {item.score:.4f}\")\n",
    "    print(f\"   Title: {item.value['title']}\")\n",
    "    print(f\"   Category: {item.value['category']}\")\n",
    "    print(f\"   Tags: {', '.join(item.value['tags'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Field-Specific Embedding\n",
    "\n",
    "Control which fields are embedded using the `index` parameter in `aput()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def insert_with_field_control():\n",
    "    \"\"\"Demonstrate field-specific embedding control.\"\"\"\n",
    "    \n",
    "    async with AsyncScyllaDBStore.from_contact_points(\n",
    "        contact_points=[\"127.0.0.1\"],\n",
    "        keyspace=\"notebook_demo\",\n",
    "        index=index_config,\n",
    "        enable_circuit_breaker=False\n",
    "    ) as store:\n",
    "        \n",
    "        await store.setup()  # Ensure prepared statements are ready\n",
    "        \n",
    "        # Insert with only title and content embedded (not metadata)\n",
    "        await store.aput(\n",
    "            namespace=(\"knowledge\", \"tech\"),\n",
    "            key=\"custom1\",\n",
    "            value={\n",
    "                \"id\": \"custom1\",\n",
    "                \"title\": \"Kubernetes Orchestration\",\n",
    "                \"content\": \"Kubernetes automates deployment, scaling, and management of containerized applications across clusters.\",\n",
    "                \"category\": \"Cloud\",\n",
    "                \"metadata\": \"Internal doc - do not embed this field\",\n",
    "                \"secret_key\": \"xyz123\"  # Won't be embedded\n",
    "            },\n",
    "            index=[\"title\", \"content\"],  # Only embed these fields\n",
    "            wait_for_vector_sync=True\n",
    "        )\n",
    "        \n",
    "        print(\"✓ Inserted document with field-specific embedding\")\n",
    "        print(\"  Embedded fields: title, content\")\n",
    "        print(\"  Skipped fields: metadata, secret_key\\n\")\n",
    "        \n",
    "        # Insert without embedding\n",
    "        await store.aput(\n",
    "            namespace=(\"knowledge\", \"tech\"),\n",
    "            key=\"temp1\",\n",
    "            value={\n",
    "                \"id\": \"temp1\",\n",
    "                \"title\": \"Temporary Data\",\n",
    "                \"content\": \"This is temporary and won't be searchable\"\n",
    "            },\n",
    "            index=False,  # Skip embedding entirely\n",
    "            wait_for_vector_sync=True\n",
    "        )\n",
    "        \n",
    "        print(\"✓ Inserted document without embedding (index=False)\")\n",
    "        print(\"  This document won't appear in semantic search\\n\")\n",
    "        \n",
    "        # Verify semantic search finds custom1 but not temp1\n",
    "        results = await store.asearch(\n",
    "            (\"knowledge\", \"tech\"),\n",
    "            query=\"container orchestration kubernetes\",\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "        custom1_found = any(item.key == \"custom1\" for item in results)\n",
    "        temp1_found = any(item.key == \"temp1\" for item in results)\n",
    "        \n",
    "        print(\"Semantic search results:\")\n",
    "        print(f\"  custom1 found: {custom1_found}\")\n",
    "        print(f\"  temp1 found: {temp1_found}\")\n",
    "        \n",
    "        if custom1_found:\n",
    "            custom1_result = [item for item in results if item.key == \"custom1\"][0]\n",
    "            print(f\"\\n  custom1 score: {custom1_result.score:.4f}\")\n",
    "            print(f\"  custom1 title: {custom1_result.value['title']}\")\n",
    "\n",
    "await insert_with_field_control()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Metrics\n",
    "\n",
    "View query statistics and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_metrics():\n",
    "    \"\"\"Display store performance metrics.\"\"\"\n",
    "    \n",
    "    async with AsyncScyllaDBStore.from_contact_points(\n",
    "        contact_points=[\"127.0.0.1\"],\n",
    "        keyspace=\"notebook_demo\",\n",
    "        index=index_config,\n",
    "        enable_circuit_breaker=False\n",
    "    ) as store:\n",
    "        \n",
    "        await store.setup()  # Ensure prepared statements are ready\n",
    "        \n",
    "        stats = store.metrics.get_stats()\n",
    "        \n",
    "        print(\"Store Performance Metrics\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total queries:      {stats['total_queries']}\")\n",
    "        print(f\"Average latency:    {stats['avg_latency_ms']:.2f} ms\")\n",
    "        print(f\"Min latency:        {stats['min_latency_ms']:.2f} ms\")\n",
    "        print(f\"Max latency:        {stats['max_latency_ms']:.2f} ms\")\n",
    "        print(f\"Error rate:         {stats['error_rate']:.2%}\")\n",
    "\n",
    "await show_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Search\n",
    "\n",
    "Try your own queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own query\n",
    "your_query = \"programming languages for data science\"  # Change this!\n",
    "\n",
    "print(f\"Your Query: '{your_query}'\\n\")\n",
    "results = await semantic_search(your_query, limit=5)\n",
    "\n",
    "for i, item in enumerate(results, 1):\n",
    "    print(f\"{i}. Score: {item.score:.4f} | {item.value['title']}\")\n",
    "    print(f\"   {item.value['content'][:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Optionally clean up all test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with AsyncScyllaDBStore.from_contact_points(\n",
    "        contact_points=[\"127.0.0.1\"],\n",
    "        keyspace=\"notebook_demo\",\n",
    "        enable_circuit_breaker=False\n",
    "    ) as store:\n",
    "\n",
    "    await store.setup()\n",
    "\n",
    "    # List all namespaces\n",
    "    namespaces = await store.alist_namespaces()\n",
    "        \n",
    "    # Delete all items in each namespace\n",
    "    for ns in namespaces:\n",
    "        items = await store.asearch(ns, limit=1000)\n",
    "        for item in items:\n",
    "            await store.adelete(item.namespace, item.key)\n",
    "            print(f\"Deleted: {item.namespace} / {item.key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ **IndexConfig** - Configure semantic search with Gemini embeddings\n",
    "2. ✅ **Auto-embedding** - Embeddings generated automatically on `aput()`\n",
    "3. ✅ **Semantic search** - Natural language queries with similarity ranking\n",
    "4. ✅ **Filtered search** - Combine metadata filters with semantic search\n",
    "5. ✅ **Field control** - Choose which fields to embed\n",
    "6. ✅ **Performance** - Query metrics and latency tracking\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Vector Storage**: ScyllaDB `VECTOR<FLOAT, 3072>` column\n",
    "- **Embeddings**: Google Gemini `gemini-embedding-001`\n",
    "- **Similarity**: sklearn `cosine_similarity` for efficient batch computation\n",
    "- **Compatible**: LangGraph BaseStore interface\n",
    "\n",
    "### Architecture Notes\n",
    "\n",
    "**How it works:**\n",
    "1. Documents are inserted with `aput()` which automatically generates embeddings\n",
    "2. Search queries are embedded using the same model\n",
    "3. Cosine similarity is computed between query and all document embeddings\n",
    "4. Results are ranked by similarity score (higher = more relevant)\n",
    "\n",
    "**Important:** Each time you create a new store instance with `from_contact_points()`, you must call `await store.setup()` to prepare statements. The notebook cells each create independent instances, so they don't share metrics.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different queries and see how well semantic search works\n",
    "- Experiment with different embedding models (OpenAI, Cohere, etc.)\n",
    "- Add more documents and test performance at scale\n",
    "- Combine with hybrid search (keyword + semantic)\n",
    "- Use a single store instance across cells to accumulate metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
